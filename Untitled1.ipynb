{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/SSD2/conda/anaconda3/envs/py_35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting Mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting Mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting Mnist_data/t10k-labels-idx1-ubyte.gz\n",
      "Eppoch: 000/050 cost: 1.177038317 train_acc: 0.879 test_acc: 0.856\n",
      "Eppoch: 005/050 cost: 0.440928231 train_acc: 0.919 test_acc: 0.896\n",
      "Eppoch: 010/050 cost: 0.383336046 train_acc: 0.929 test_acc: 0.904\n",
      "Eppoch: 015/050 cost: 0.357275752 train_acc: 0.939 test_acc: 0.909\n",
      "Eppoch: 020/050 cost: 0.341507399 train_acc: 0.939 test_acc: 0.913\n",
      "Eppoch: 025/050 cost: 0.330522004 train_acc: 0.939 test_acc: 0.914\n",
      "Eppoch: 030/050 cost: 0.322351353 train_acc: 0.939 test_acc: 0.916\n",
      "Eppoch: 035/050 cost: 0.315924035 train_acc: 0.939 test_acc: 0.917\n",
      "Eppoch: 040/050 cost: 0.310749289 train_acc: 0.939 test_acc: 0.917\n",
      "Eppoch: 045/050 cost: 0.306392209 train_acc: 0.939 test_acc: 0.919\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 读入数据  ‘MNIST_data’ 是我保存数据的文件夹的名称\n",
    "mnist = input_data.read_data_sets('Mnist_data/', one_hot=True)\n",
    "\n",
    "# 各种图片数据以及标签 images是图像数据  labels 是正确的结果\n",
    "trainimg = mnist.train.images\n",
    "trainlabels = mnist.train.labels\n",
    "testimg = mnist.test.images\n",
    "testlabels = mnist.test.labels\n",
    "\n",
    "# 输入的数据 每张图片的大小是 28 * 28，在提供的数据集中已经被展平乘了 1 * 784（28 * 28）的向量\n",
    "# 方便矩阵乘法处理\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "# 输出的结果是对于每一张图输出的是 1*10 的向量，例如 [1, 0, 0, 0...]\n",
    "# 只有一个数字是1 所在的索引表示预测数据\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 模型参数\n",
    "# 对于这样的全连接方式 某一层的参数矩阵的行数是输入数据的数量 ，列数是这一层的神经元个数\n",
    "# 这一点用线性代数的思想考虑会比较好理解\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "# 偏置\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# 建立模型 并使用softmax（）函数对输出的数据进行处理\n",
    "# softmax（） 函数比较重要 后面写\n",
    "# 这里注意理解一下 模型输出的actv的shape 后边会有用（n * 10, n时输入的数据的数量）\n",
    "actv = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# 损失函数 使用交叉熵的方式  softmax（）函数与交叉熵一般都会结合使用\n",
    "# clip_by_value()函数可以将数组整理在一个范围内，后面会具体解释\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(tf.clip_by_value(actv, 1e-10, 1.0)), reduction_indices=1))\n",
    "\n",
    "# 使用梯度下降的方法进行参数优化\n",
    "learning_rate = 0.01\n",
    "optm = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# 判断是否预测结果与正确结果是否一致\n",
    "# 注意这里使用的函数的 argmax（）也就是比较的是索引 索引才体现了预测的是哪个数字\n",
    "# 并且 softmax（）函数的输出不是[1, 0, 0...] 类似的数组 不会与正确的label相同\n",
    "# pred 数组的输出是  [True, False, True...] 类似的\n",
    "pred = tf.equal(tf.argmax(actv, 1), tf.argmax(y, 1))\n",
    "\n",
    "# 计算正确率\n",
    "# 上面看到pred数组的形式 使用cast转化为浮点数 则 True会被转化为 1.0, False 0.0\n",
    "# 所以对这些数据求均值 就是正确率了（这个均值表示所有数据中有多少个1 -> True的数量 ->正确个数）\n",
    "accr = tf.reduce_mean(tf.cast(pred, tf.float32))\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# 接下来要使用的一些常量 可能会自己根据情况调整所以都定义在这里\n",
    "training_epochs = 50  # 一共要训练的轮数\n",
    "batch_size = 100  # 每一批训练数据的数量\n",
    "display_step = 5  # 用来比较、输出结果\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    # 对于每一轮训练\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        # 计算训练数据可以划分多少个batch大小的组\n",
    "        num_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        # 每一组每一组地训练\n",
    "        for i in range(num_batch):\n",
    "            # 这里地 mnist.train.next_batch()作用是：\n",
    "            # 第一次取1-10数据 第二次取 11-20 ... 类似这样\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # 运行模型进行训练\n",
    "            sess.run(optm, feed_dict={x: batch_xs, y: batch_ys})\n",
    "            # 如果觉得上面 feed_dict 的不方便 也可以提前写在外边\n",
    "            feeds = {x: batch_xs, y: batch_ys}\n",
    "            # 累计计算总的损失值\n",
    "            avg_cost += sess.run(cost, feed_dict=feeds) / num_batch\n",
    "\n",
    "        # 输出一些数据\n",
    "        if epoch % display_step == 0:\n",
    "            # 为了输出在训练集上的正确率本来应该使用全部的train数据 这里为了快一点就只用了部分数据\n",
    "            feed_train = {x: trainimg[1: 100], y: trainlabels[1: 100]}\n",
    "            # 在测试集上运行模型\n",
    "            feedt_test = {x: mnist.test.images, y: mnist.test.labels}\n",
    "            train_acc = sess.run(accr, feed_dict=feed_train)\n",
    "            test_acc = sess.run(accr, feed_dict=feedt_test)\n",
    "\n",
    "            print(\"Eppoch: %03d/%03d cost: %.9f train_acc: %.3f test_acc: %.3f\" %\n",
    "                  (epoch, training_epochs, avg_cost, train_acc, test_acc))\n",
    "print(\"Done.\")\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
